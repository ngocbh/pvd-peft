Thu Nov 30 02:58:41 EST 2023
r904u07n04.grace.ycrc.yale.edu
/home/nhb25/palmer_scratch/pre-training-via-denoising
/vast/palmer/scratch/ying_rex/nhb25/pre-training-via-denoising
./scripts/train.sh qm9_peft
Global seed set to 1
/home/nhb25/.conda/envs/pvd/lib/python3.9/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/nhb25/.conda/envs/pvd/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(load_model=None, conf=None, num_epochs=3000, num_steps=300000, batch_size=128, inference_batch_size=128, lr=0.0004, lr_schedule='cosine', lr_patience=15, lr_min=1e-07, lr_factor=0.8, lr_warmup_steps=10000, lr_cosine_length=300000, early_stopping_patience=1500, weight_decay=0.0, ema_alpha_y=1.0, ema_alpha_dy=1.0, ngpus=-1, num_nodes=1, precision=32, log_dir='experiments/qm9_peft', splits=None, train_size=110000, val_size=10000, test_size=None, test_interval=10, save_interval=10, seed=1, distributed_backend='ddp', num_workers=6, redirect=False, wandb_notes='', job_id='qm9_peft', pretrained_model='checkpoints/denoised-pcqm4mv2.ckpt', peft='ia3', dataset='QM9', dataset_root='data/qm9', dataset_arg='homo', coord_files=None, embed_files=None, energy_files=None, force_files=None, energy_weight=1.0, force_weight=1.0, position_noise_scale=0.005, denoising_weight=0.1, denoising_only=False, model='equivariant-transformer-ia3', output_model='Scalar', prior_model=None, output_model_noise='VectorOutput', embedding_dimension=256, num_layers=8, num_rbf=64, activation='silu', rbf_type='expnorm', trainable_rbf=False, neighbor_embedding=True, aggr='add', distance_influence='both', attn_activation='silu', num_heads=8, layernorm_on_vec='whitened', derivative=False, cutoff_lower=0.0, cutoff_upper=5.0, atom_filter=-1, max_z=100, max_num_neighbors=32, standardize=True, reduce_op='add')
train 110000, val 10000, test 10831
computing mean and std:   0%|          | 0/860 [00:00<?, ?it/s]computing mean and std:   0%|          | 1/860 [00:02<38:29,  2.69s/it]computing mean and std:   0%|          | 4/860 [00:02<08:13,  1.73it/s]computing mean and std:   1%|          | 6/860 [00:03<05:06,  2.78it/s]computing mean and std:   1%|▏         | 12/860 [00:03<01:59,  7.12it/s]computing mean and std:   2%|▏         | 16/860 [00:03<01:23, 10.11it/s]computing mean and std:   2%|▏         | 21/860 [00:03<01:00, 13.87it/s]computing mean and std:   3%|▎         | 24/860 [00:04<01:40,  8.36it/s]computing mean and std:   3%|▎         | 30/860 [00:04<01:14, 11.14it/s]computing mean and std:   4%|▍         | 34/860 [00:04<00:59, 13.78it/s]computing mean and std:   4%|▍         | 37/860 [00:04<00:55, 14.92it/s]computing mean and std:   5%|▍         | 42/860 [00:05<00:47, 17.23it/s]computing mean and std:   6%|▌         | 48/860 [00:05<00:40, 20.28it/s]computing mean and std:   6%|▋         | 54/860 [00:05<00:35, 22.83it/s]computing mean and std:   7%|▋         | 60/860 [00:05<00:33, 24.17it/s]computing mean and std:   8%|▊         | 66/860 [00:05<00:30, 25.66it/s]computing mean and std:   8%|▊         | 72/860 [00:06<00:29, 26.61it/s]computing mean and std:   9%|▉         | 78/860 [00:06<00:28, 27.09it/s]computing mean and std:  10%|▉         | 84/860 [00:06<00:28, 27.62it/s]computing mean and std:  10%|█         | 90/860 [00:06<00:27, 28.02it/s]computing mean and std:  11%|█         | 96/860 [00:06<00:27, 28.13it/s]computing mean and std:  12%|█▏        | 102/860 [00:07<00:27, 27.70it/s]computing mean and std:  13%|█▎        | 108/860 [00:07<00:26, 28.63it/s]computing mean and std:  13%|█▎        | 114/860 [00:07<00:26, 28.54it/s]computing mean and std:  14%|█▍        | 120/860 [00:07<00:25, 28.56it/s]computing mean and std:  15%|█▍        | 126/860 [00:07<00:25, 28.71it/s]computing mean and std:  15%|█▌        | 132/860 [00:08<00:25, 28.71it/s]computing mean and std:  16%|█▌        | 138/860 [00:08<00:25, 28.82it/s]computing mean and std:  17%|█▋        | 144/860 [00:08<00:24, 28.89it/s]computing mean and std:  17%|█▋        | 150/860 [00:08<00:24, 28.73it/s]computing mean and std:  18%|█▊        | 156/860 [00:09<00:24, 28.89it/s]computing mean and std:  19%|█▉        | 162/860 [00:09<00:23, 29.29it/s]computing mean and std:  20%|█▉        | 168/860 [00:09<00:23, 29.04it/s]computing mean and std:  20%|██        | 174/860 [00:09<00:23, 29.21it/s]computing mean and std:  21%|██        | 180/860 [00:09<00:22, 29.70it/s]computing mean and std:  22%|██▏       | 186/860 [00:10<00:22, 29.37it/s]computing mean and std:  22%|██▏       | 192/860 [00:10<00:21, 30.41it/s]computing mean and std:  23%|██▎       | 198/860 [00:10<00:22, 29.58it/s]computing mean and std:  24%|██▎       | 204/860 [00:10<00:20, 32.05it/s]computing mean and std:  24%|██▍       | 210/860 [00:10<00:23, 27.32it/s]computing mean and std:  25%|██▌       | 216/860 [00:11<00:22, 28.56it/s]computing mean and std:  26%|██▌       | 222/860 [00:11<00:39, 16.28it/s]computing mean and std:  27%|██▋       | 228/860 [00:12<00:36, 17.48it/s]computing mean and std:  27%|██▋       | 234/860 [00:12<00:32, 19.03it/s]computing mean and std:  28%|██▊       | 240/860 [00:12<00:29, 21.03it/s]computing mean and std:  29%|██▊       | 246/860 [00:12<00:26, 23.13it/s]computing mean and std:  29%|██▉       | 251/860 [00:12<00:22, 26.68it/s]computing mean and std:  30%|██▉       | 255/860 [00:12<00:21, 27.95it/s]computing mean and std:  30%|███       | 259/860 [00:13<00:24, 24.84it/s]computing mean and std:  31%|███       | 264/860 [00:13<00:24, 24.51it/s]computing mean and std:  31%|███▏      | 270/860 [00:13<00:22, 25.79it/s]computing mean and std:  32%|███▏      | 276/860 [00:13<00:22, 26.53it/s]computing mean and std:  33%|███▎      | 282/860 [00:14<00:21, 27.34it/s]computing mean and std:  33%|███▎      | 288/860 [00:14<00:20, 27.26it/s]computing mean and std:  34%|███▍      | 294/860 [00:14<00:20, 27.40it/s]computing mean and std:  35%|███▍      | 300/860 [00:14<00:20, 27.78it/s]computing mean and std:  36%|███▌      | 306/860 [00:14<00:19, 27.82it/s]computing mean and std:  36%|███▋      | 312/860 [00:15<00:19, 27.68it/s]computing mean and std:  37%|███▋      | 318/860 [00:15<00:18, 28.85it/s]computing mean and std:  38%|███▊      | 324/860 [00:15<00:19, 27.58it/s]computing mean and std:  38%|███▊      | 330/860 [00:15<00:19, 27.31it/s]computing mean and std:  39%|███▉      | 336/860 [00:15<00:18, 28.06it/s]computing mean and std:  40%|███▉      | 342/860 [00:16<00:18, 28.05it/s]computing mean and std:  40%|████      | 348/860 [00:16<00:18, 27.06it/s]computing mean and std:  41%|████      | 354/860 [00:16<00:18, 28.11it/s]computing mean and std:  42%|████▏     | 359/860 [00:16<00:16, 29.59it/s]computing mean and std:  43%|████▎     | 366/860 [00:17<00:18, 27.33it/s]computing mean and std:  43%|████▎     | 372/860 [00:17<00:17, 27.86it/s]computing mean and std:  44%|████▍     | 377/860 [00:17<00:15, 31.45it/s]computing mean and std:  44%|████▍     | 381/860 [00:17<00:14, 32.04it/s]computing mean and std:  45%|████▍     | 385/860 [00:17<00:17, 27.68it/s]computing mean and std:  45%|████▌     | 390/860 [00:17<00:18, 25.43it/s]computing mean and std:  46%|████▌     | 396/860 [00:18<00:15, 29.19it/s]computing mean and std:  47%|████▋     | 402/860 [00:18<00:17, 25.68it/s]computing mean and std:  47%|████▋     | 408/860 [00:18<00:16, 26.61it/s]computing mean and std:  48%|████▊     | 414/860 [00:18<00:16, 26.61it/s]computing mean and std:  49%|████▉     | 420/860 [00:19<00:19, 22.15it/s]computing mean and std:  49%|████▉     | 425/860 [00:19<00:16, 25.85it/s]computing mean and std:  50%|████▉     | 429/860 [00:19<00:30, 14.14it/s]computing mean and std:  50%|█████     | 432/860 [00:20<00:31, 13.78it/s]computing mean and std:  51%|█████     | 438/860 [00:20<00:26, 15.87it/s]computing mean and std:  52%|█████▏    | 444/860 [00:20<00:22, 18.77it/s]computing mean and std:  52%|█████▏    | 450/860 [00:20<00:19, 21.22it/s]computing mean and std:  53%|█████▎    | 456/860 [00:21<00:17, 22.88it/s]computing mean and std:  54%|█████▎    | 462/860 [00:21<00:16, 24.47it/s]computing mean and std:  54%|█████▍    | 468/860 [00:21<00:15, 25.28it/s]computing mean and std:  55%|█████▌    | 474/860 [00:21<00:14, 26.59it/s]computing mean and std:  56%|█████▌    | 480/860 [00:21<00:14, 26.61it/s]computing mean and std:  57%|█████▋    | 486/860 [00:22<00:13, 27.41it/s]computing mean and std:  57%|█████▋    | 492/860 [00:22<00:13, 27.44it/s]computing mean and std:  58%|█████▊    | 498/860 [00:22<00:12, 27.94it/s]computing mean and std:  59%|█████▊    | 504/860 [00:22<00:12, 28.43it/s]computing mean and std:  59%|█████▉    | 510/860 [00:23<00:12, 27.75it/s]computing mean and std:  60%|██████    | 516/860 [00:23<00:11, 29.17it/s]computing mean and std:  61%|██████    | 522/860 [00:23<00:10, 31.44it/s]computing mean and std:  61%|██████▏   | 528/860 [00:23<00:11, 28.39it/s]computing mean and std:  62%|██████▏   | 534/860 [00:23<00:11, 28.87it/s]computing mean and std:  63%|██████▎   | 540/860 [00:24<00:10, 29.75it/s]computing mean and std:  63%|██████▎   | 546/860 [00:24<00:10, 29.46it/s]computing mean and std:  64%|██████▍   | 552/860 [00:24<00:10, 28.15it/s]computing mean and std:  65%|██████▍   | 558/860 [00:24<00:09, 31.15it/s]computing mean and std:  66%|██████▌   | 564/860 [00:24<00:09, 30.00it/s]computing mean and std:  66%|██████▋   | 570/860 [00:25<00:09, 29.87it/s]computing mean and std:  67%|██████▋   | 576/860 [00:25<00:08, 33.52it/s]computing mean and std:  67%|██████▋   | 580/860 [00:25<00:08, 34.65it/s]computing mean and std:  68%|██████▊   | 584/860 [00:25<00:07, 34.87it/s]computing mean and std:  68%|██████▊   | 588/860 [00:25<00:09, 27.38it/s]computing mean and std:  69%|██████▉   | 594/860 [00:25<00:09, 28.30it/s]computing mean and std:  70%|██████▉   | 598/860 [00:25<00:08, 30.21it/s]computing mean and std:  70%|███████   | 602/860 [00:26<00:09, 27.17it/s]computing mean and std:  70%|███████   | 606/860 [00:26<00:09, 26.21it/s]computing mean and std:  71%|███████   | 612/860 [00:26<00:09, 25.44it/s]computing mean and std:  72%|███████▏  | 618/860 [00:26<00:08, 27.85it/s]computing mean and std:  72%|███████▏  | 623/860 [00:26<00:07, 31.24it/s]computing mean and std:  73%|███████▎  | 627/860 [00:26<00:08, 28.23it/s]computing mean and std:  73%|███████▎  | 630/860 [00:27<00:08, 27.90it/s]computing mean and std:  74%|███████▍  | 636/860 [00:27<00:08, 26.73it/s]computing mean and std:  75%|███████▍  | 642/860 [00:27<00:07, 28.68it/s]computing mean and std:  75%|███████▌  | 648/860 [00:27<00:08, 26.26it/s]computing mean and std:  76%|███████▌  | 654/860 [00:27<00:07, 29.11it/s]computing mean and std:  77%|███████▋  | 660/860 [00:28<00:07, 27.99it/s]computing mean and std:  77%|███████▋  | 663/860 [00:28<00:08, 22.52it/s]computing mean and std:  78%|███████▊  | 667/860 [00:28<00:07, 24.25it/s]computing mean and std:  78%|███████▊  | 670/860 [00:28<00:08, 23.22it/s]computing mean and std:  78%|███████▊  | 675/860 [00:28<00:07, 24.73it/s]computing mean and std:  79%|███████▉  | 681/860 [00:29<00:06, 25.72it/s]computing mean and std:  80%|███████▉  | 687/860 [00:29<00:06, 26.14it/s]computing mean and std:  81%|████████  | 693/860 [00:29<00:05, 28.50it/s]computing mean and std:  81%|████████  | 697/860 [00:30<00:13, 12.36it/s]computing mean and std:  81%|████████▏ | 700/860 [00:30<00:12, 13.19it/s]computing mean and std:  82%|████████▏ | 706/860 [00:30<00:09, 15.68it/s]computing mean and std:  83%|████████▎ | 711/860 [00:31<00:08, 18.19it/s]computing mean and std:  83%|████████▎ | 717/860 [00:31<00:06, 21.88it/s]computing mean and std:  84%|████████▍ | 722/860 [00:31<00:05, 25.67it/s]computing mean and std:  84%|████████▍ | 726/860 [00:31<00:05, 25.34it/s]computing mean and std:  85%|████████▍ | 729/860 [00:31<00:05, 24.52it/s]computing mean and std:  85%|████████▌ | 734/860 [00:31<00:04, 27.43it/s]computing mean and std:  86%|████████▌ | 738/860 [00:31<00:04, 27.67it/s]computing mean and std:  86%|████████▋ | 742/860 [00:32<00:04, 26.08it/s]computing mean and std:  87%|████████▋ | 747/860 [00:32<00:03, 30.60it/s]computing mean and std:  87%|████████▋ | 751/860 [00:32<00:03, 30.09it/s]computing mean and std:  88%|████████▊ | 755/860 [00:32<00:04, 25.63it/s]computing mean and std:  88%|████████▊ | 759/860 [00:32<00:04, 24.36it/s]computing mean and std:  89%|████████▉ | 765/860 [00:32<00:03, 30.17it/s]computing mean and std:  89%|████████▉ | 769/860 [00:32<00:02, 32.09it/s]computing mean and std:  90%|████████▉ | 773/860 [00:33<00:03, 27.39it/s]computing mean and std:  90%|█████████ | 777/860 [00:33<00:03, 25.60it/s]computing mean and std:  91%|█████████ | 782/860 [00:33<00:02, 30.31it/s]computing mean and std:  91%|█████████▏| 786/860 [00:33<00:02, 27.96it/s]computing mean and std:  92%|█████████▏| 790/860 [00:33<00:02, 27.99it/s]computing mean and std:  92%|█████████▏| 795/860 [00:33<00:02, 28.01it/s]computing mean and std:  93%|█████████▎| 800/860 [00:34<00:01, 32.04it/s]computing mean and std:  93%|█████████▎| 804/860 [00:34<00:01, 30.14it/s]computing mean and std:  94%|█████████▍| 808/860 [00:34<00:01, 28.80it/s]computing mean and std:  95%|█████████▍| 813/860 [00:34<00:01, 26.04it/s]computing mean and std:  95%|█████████▍| 816/860 [00:34<00:01, 26.69it/s]computing mean and std:  95%|█████████▌| 821/860 [00:34<00:01, 28.65it/s]computing mean and std:  96%|█████████▌| 825/860 [00:34<00:01, 28.55it/s]computing mean and std:  96%|█████████▋| 829/860 [00:35<00:01, 30.58it/s]computing mean and std:  97%|█████████▋| 833/860 [00:35<00:00, 29.20it/s]computing mean and std:  97%|█████████▋| 837/860 [00:35<00:00, 27.45it/s]computing mean and std:  98%|█████████▊| 841/860 [00:35<00:00, 29.83it/s]computing mean and std:  98%|█████████▊| 845/860 [00:35<00:00, 29.84it/s]computing mean and std:  99%|█████████▊| 849/860 [00:35<00:00, 28.59it/s]computing mean and std: 100%|██████████| 860/860 [00:35<00:00, 23.93it/s]
/home/nhb25/.conda/envs/pvd/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:360: UserWarning: Checkpoint directory experiments/qm9_peft exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
/home/nhb25/.conda/envs/pvd/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:396: LightningDeprecationWarning: Argument `period` in `ModelCheckpoint` is deprecated in v1.3 and will be removed in v1.5. Please use `every_n_val_epochs` instead.
  rank_zero_deprecation(
wandb: W&B API key is configured (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.11
wandb: Run data is saved locally in /vast/palmer/scratch/ying_rex/nhb25/pre-training-via-denoising/wandb/run-20231130_025928-3lvycot5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run qm9_peft
wandb: ⭐️ View project at https://wandb.ai/ngocjr7/pre-training-via-denoising
wandb: 🚀 View run at https://wandb.ai/ngocjr7/pre-training-via-denoising/runs/3lvycot5
Traceback (most recent call last):
  File "/vast/palmer/scratch/ying_rex/nhb25/pre-training-via-denoising/scripts/train.py", line 208, in <module>
    main()
  File "/vast/palmer/scratch/ying_rex/nhb25/pre-training-via-denoising/scripts/train.py", line 185, in main
    trainer = pl.Trainer(
  File "/home/nhb25/.conda/envs/pvd/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/env_vars_connector.py", line 40, in insert_env_defaults
    return fn(self, **kwargs)
  File "/home/nhb25/.conda/envs/pvd/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 321, in __init__
    self.accelerator_connector = AcceleratorConnector(
  File "/home/nhb25/.conda/envs/pvd/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 131, in __init__
    self.parallel_device_ids = device_parser.parse_gpu_ids(self.gpus)
  File "/home/nhb25/.conda/envs/pvd/lib/python3.9/site-packages/pytorch_lightning/utilities/device_parser.py", line 81, in parse_gpu_ids
    raise MisconfigurationException("GPUs requested but none are available.")
pytorch_lightning.utilities.exceptions.MisconfigurationException: GPUs requested but none are available.
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.166 MB of 0.166 MB uploaded (0.000 MB deduped)wandb: \ 0.166 MB of 0.166 MB uploaded (0.000 MB deduped)wandb: | 0.166 MB of 0.166 MB uploaded (0.000 MB deduped)wandb: / 0.166 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: - 0.166 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: \ 0.166 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: | 0.166 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: / 0.166 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: - 0.166 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: \ 0.166 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: | 0.166 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: / 0.166 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: - 0.166 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: \ 0.166 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: | 0.166 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: / 0.166 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: - 0.166 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: \ 0.166 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: | 0.166 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: / 0.166 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: - 0.166 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: \ 0.166 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: | 0.167 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: / 0.167 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: - 0.167 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: \ 0.167 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: | 0.176 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: / 0.176 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: - 0.176 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: \ 0.177 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: | 0.177 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: / 0.177 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: - 0.177 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: \ 0.177 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: | 0.177 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: / 0.180 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: - 0.180 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: \ 0.180 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: | 0.180 MB of 0.180 MB uploaded (0.000 MB deduped)wandb: / 0.180 MB of 0.180 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: Synced qm9_peft: https://wandb.ai/ngocjr7/pre-training-via-denoising/runs/3lvycot5
wandb: Synced 6 W&B file(s), 0 media file(s), 53 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231130_025928-3lvycot5/logs

All done in sbatch.
Thu Nov 30 03:00:49 EST 2023
